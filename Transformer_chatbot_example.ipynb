{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformer_chatbot_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T39h16jbjhgnGqPjgiQCVi31nbmG9aq3",
      "authorship_tag": "ABX9TyMnazQnkLPqdZugzjp/0DSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobby-lie/transformer_chatbot_example/blob/main/Transformer_chatbot_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0bGH58GbyYe"
      },
      "source": [
        "# This transformer chat bot is based on this notebook, with changes made to suit our use-case: https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUvE71z2Upns",
        "outputId": "2f4ee227-2d1e-42e9-9bd2-52e929da5de0"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "if 'google.colab' in sys.modules:\r\n",
        "  %tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf.random.set_seed(1234)\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "#!pip install tensorflow-datasets==1.2.0\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "import os\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBsrrhM3UsXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb207ea-aee2-4a71-ce49-8a2c3bfd66ef"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUNFe-kRaiUe"
      },
      "source": [
        "# GPU/TPU initialization\r\n",
        "\r\n",
        "Select either TPU or GPU hardware accelerator in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4hiqNjgUwLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f03dfc5-028e-42dd-cc13-5d5b5ea79588"
      },
      "source": [
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPLICAS: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFRV0C8Gaufx"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM8AK6HPU34t"
      },
      "source": [
        "# Maximum sentence length\r\n",
        "MAX_LENGTH = 30\r\n",
        "\r\n",
        "# For tf.data.Dataset\r\n",
        "BATCH_SIZE = int(64 * strategy.num_replicas_in_sync)\r\n",
        "BUFFER_SIZE = 20000\r\n",
        "\r\n",
        "# For Transformer\r\n",
        "NUM_LAYERS = 2 #6\r\n",
        "D_MODEL = 256 #512\r\n",
        "NUM_HEADS = 8\r\n",
        "UNITS = 512 #2048\r\n",
        "DROPOUT = 0.1\r\n",
        "\r\n",
        "EPOCHS = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h0e4m7kazMW"
      },
      "source": [
        "# The dataset is based on the Twitter conversational data which consists of 2-turn conversations\r\n",
        "\r\n",
        "# We must extract conversation initiations as well as responses, remove special characters in the sentences, build a tokenizer to map text to ID and vice versa, tokenize each sentence as well as add start and end tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFe9f6cmU9qH"
      },
      "source": [
        "def textPreprocess(input_text):\r\n",
        "\r\n",
        "  def removeAccents(input_text):\r\n",
        "      strange='ąćęłńóśżź'\r\n",
        "      ascii_replacements='acelnoszz'\r\n",
        "      translator=str.maketrans(strange,ascii_replacements)\r\n",
        "      return input_text.translate(translator)\r\n",
        "\r\n",
        "  def removeSpecial(input_text):\r\n",
        "      special='[^A-Za-z0-9 ]+'\r\n",
        "      return re.sub(special, '', input_text)\r\n",
        "\r\n",
        "  def removeTriplicated(input_text):\r\n",
        "      return re.compile(r'(.)\\1{2,}', re.IGNORECASE).sub(r'\\1', input_text)\r\n",
        "\r\n",
        "  return removeTriplicated(removeSpecial(removeAccents(input_text.lower())))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSpJ0XVcVZc_"
      },
      "source": [
        "initiates = []\r\n",
        "responses = []\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/OSN_Project/data.txt', 'r', encoding=\"utf-8\") as file:\r\n",
        "    lines = file.readlines()\r\n",
        "    for line in lines:\r\n",
        "        if '|||' in line:\r\n",
        "            initiates.append(line.split('|||')[0])\r\n",
        "            responses.append(line.split('|||')[1])\r\n",
        "#             print(line.split('|||'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoLH5QxzVajj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6211f48e-3cc2-48df-8527-c8867c5ed53f"
      },
      "source": [
        "len(initiates)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaRQA7NlVmYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecec2bfe-2bf5-4d37-84ec-5e4e8208a2d8"
      },
      "source": [
        "len(responses)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2620icYWu2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d1afe7-8f2b-45af-fa07-b24561c0084e"
      },
      "source": [
        "print('Sample initiation: {}'.format(initiates[20]))\r\n",
        "print(\"\\n\")\r\n",
        "print('Sample response: {}'.format(responses[20]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample initiation: congrats to you and to all of the virtual conference speakers . hopefully , we will still socialize in the evenings and mornings like irl . just think - - no long lines for the restrooms and elevators . \n",
            "\n",
            "\n",
            "Sample response:  thanks ! yes , i think some online socializing is a great idea - i will miss the dancing , tho !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7A3SLmPXBH-"
      },
      "source": [
        "text_preprocessor = lambda x: textPreprocess(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVtr8CAVXDzU"
      },
      "source": [
        "initiates_preprocessed = list(map(text_preprocessor, initiates))\r\n",
        "responses_preprocessed = list(map(text_preprocessor, responses))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQha_kcxXErQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c74f2bf1-6915-4202-ff4f-d9f4aab90f51"
      },
      "source": [
        "initiates_preprocessed[20]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'congrats to you and to all of the virtual conference speakers  hopefully  we will still socialize in the evenings and mornings like irl  just think no long lines for the restrooms and elevators  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCTqT-AeXGHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bd0c4997-f5ce-48ce-d16c-2f7491dba52d"
      },
      "source": [
        "responses_preprocessed[20]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' thanks  yes  i think some online socializing is a great idea  i will miss the dancing  tho '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wyrhHrNXHMK"
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\r\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\r\n",
        "    initiates_preprocessed + responses_preprocessed, target_vocab_size=2**13)\r\n",
        "\r\n",
        "# Define start and end token to indicate the start and end of a sentence\r\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\r\n",
        "\r\n",
        "# Vocabulary size plus start and end token\r\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7pSdSWXNq4"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(initiates_preprocessed[20])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0J41WN-YjE3"
      },
      "source": [
        "# Tokenize, filter and pad sentences\r\n",
        "def tokenize_and_filter(inputs, outputs):\r\n",
        "  tokenized_inputs, tokenized_outputs = [], []\r\n",
        "  \r\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\r\n",
        "    # tokenize sentence\r\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\r\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\r\n",
        "    # check tokenized sentence max length\r\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\r\n",
        "      tokenized_inputs.append(sentence1)\r\n",
        "      tokenized_outputs.append(sentence2)\r\n",
        "  \r\n",
        "  # pad tokenized sentences\r\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\r\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\r\n",
        "  \r\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROId6UzZ4L1"
      },
      "source": [
        "initiates_preprocessed, responses_preprocessed = tokenize_and_filter(initiates_preprocessed, responses_preprocessed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HobMZowZ-wJ"
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\r\n",
        "print('Number of samples: {}'.format(len(initiates_preprocessed)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqjqQDTSbPA0"
      },
      "source": [
        "# We need to create the tf.data.Dataset in order to construct our input pipeline to utilize caching and prefetching to speed up the training process.\r\n",
        "\r\n",
        "# The transformer is auto-regressive so it makes predictions one part at a time and uses its output at each time step to figure out what to do next. \r\n",
        "\r\n",
        "# During training, teacher-forcing is used. This is when we pass the true output to the next time step regardless of what the model predicts at the current time step.\r\n",
        "\r\n",
        "# As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\r\n",
        "\r\n",
        "# In order to prevent the model from peaking at the expected output, the model uses a look-ahead mask. \r\n",
        "\r\n",
        "# Target is divided into decoder_inputs which padded as an input to the decoder and cropped_targets for calculating our loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssK2UcpbaQVD"
      },
      "source": [
        "# decoder inputs use the previous target as input\r\n",
        "# remove START_TOKEN from targets\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "    {\r\n",
        "        'inputs': initiates_preprocessed,\r\n",
        "        'dec_inputs': responses_preprocessed[:, :-1]\r\n",
        "    },\r\n",
        "    {\r\n",
        "        'outputs': responses_preprocessed[:, 1:]\r\n",
        "    },\r\n",
        "))\r\n",
        "\r\n",
        "dataset = dataset.cache()\r\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE)\r\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZM4sEahaU_-"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh7rX3vScMbR"
      },
      "source": [
        "# Attention\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "# Scaled product Attention\r\n",
        "\r\n",
        "The scaled dot-product attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\r\n",
        "\r\n",
        "![Capture.PNG](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqgAAABXCAYAAADI47e5AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAACaJSURBVHhe7Z39axxJmufvTyoSqpGwhrKotZHG55NaNq2RbgTWiLXdHjG6tTwnZmsbjKYtltVs0aujWzpWDJ7qRezY4xaHMNbcikHgaYHwmXabU2OMZz3jBltNUwaZPQryl+ciMiMzn8zKzIrMesuSvh8Iul2ql3yLJ77xxBPP858IAAAAAACADAGBCgAAAAAAMgUEKgAAAAAAyBQQqAAAAAAAIFNAoAIAAAAAgEwBgQoAAAAAADIFBCoAAAAAAMgUEKgAAAAAACBTQKACAAAAAIBMAYEKAAAAAAAyBQQqAAAAAADIFBCoAAAAAAAgU0CgAgAAAACATAGBCgAAAAAAMgUEKgAAAAAAyBQQqAAAAAAAIFNAoAIAAAAAgEwBgQoAAAAAADIFBCoAAAAAQJt4sz5OuVyO8qcGaXBQtgL1GTnKGX1UsP4tWqGPDPEeY25bfQpAoAIAAAAAtIU3tD4+QLNbVfVvwdEGXRJiNDe+Lv7qYNLeR6dpZOVP6t8AAhUAAAAAoB28WaefzG7Rkfqnxe4C9QuBeq78TL1g86w8QnCgekCgAgAAAAC0gTfrP6EbO6b6l82jxdOUy52mxUfqBcXuwiTBgeoBgQoAAACAY0SN3j7dpXv31mht7Z747z16sP+teLXz1N6+DfyuXPKX8aeztOXXrSHvPdlAoAIAAACg9zEP6eHqNRrOG9R3ZoKulyuWOF27NS1ey5HR9wEtPTykgC6sY7d0ytqwJDc2BVv+h/9IX6n3WfzlMxqre59BhZtfqjcEcOJPL234l/1BHRCoAAAAAOhpak9WaapgUG5gksphIrS6R4sj4u+5wIalGJzd97ncBVp9pV4MwXz4t/QD8b2TS/fp6dsGPtDtOUv8BuNPQT0QqAAAAADoWapbc1QwcmSMLNJenPZ8VqZzUnAa47QeIzgdtuekoBXvH1qmA/VakOreEo0VJ2n1id7ifFT8KagHAhUAAAAAPUl1a5YGpIgcmKXGjtE/0cqI9IjmqLjkW6gP4REtnrbf27+wq17j1OjJ6iQVx5biRbEPJ/50jrBZvzEQqOBkopZ78tP/St+rl8DJ5PvPp8gwRmhRf5QBALQR8+UGzQwYVPx4X70SQXWDLsmE97l+urqp13+3Zm3RmRtZEXI1hjfrNC7fJ9qljUC0qPmSNq4UaXhhmw4bBbRymow/3b9ZEEJ8hjZeJvnR3gUCFZw8qls0VzDIGCnTwcno5yCWGj1ZHiEjQWwaAKA9mAcrNJbP0cDsFsX3xiptXFJL8BdWSWPF3sIVqLlZ2lKvhWFuXlXvG6d1L5s+mYfbtDBcpCsbLxtutgpibs1a8aepk/Gbh7Q5O0A5MaEun4DBCwIVnCzMAyrLQHnNGCRwUnhGK9ZzcTIMPwCZpLpFswNCFA4s0G6DbmjuLthL+zmDZu7o+yN1BeruQr/9vtOL5ISLWvGm+ffo8u8STGTffE6XVTnTQp8tqN2Sp9O/pr+ot2lztE1z1jXSCWnobXpAoFbFAyVmDAkfQgDq8Z6lcajTTFJ7+5pev/6O3rVNI9bo7evXFLrR1lkuPAGGH4DM4TgPcgO00EidkilsufKehuQTjcaLQc31CxGsXq3nGZXP2e+za+ObdLA+qQRxjvpv7CT2nrYS89EiFeWx6a4Cmu/oO2H3XjfKMNAE5rvv6PV371p6XTIvUL1ZEtIygOY42p6zn6VzZWF+WoDo9H/er9CtDydoaPAU5dVzarX8KRocnaZblX36tiuZl1/R6gV2PA3aOF/DcnlDtyfVIBDVGsVxJWKXFvpDfiOkzdz5f+ozIRzdoRkrLi26hZ+v3OR7zvq7cWmjwfIi6DrmIT2uzNPoqbx9X0WfG53fpBMSnnfseLYiw2yE+AuWBQ1lm+acPp4kntPcpKvyM40+x+NPK89pe+EsFSbLtOiEFBgz1F1/2ZEQ6LaHt7j4qKEo9NJlNWjFJX+O1wBfLRXDP+e0WNGfnGwLVDGjWlazGNlOIy9DZ6nu0dIHfcJo5Kk43ygeKOOYj2ixKJ+j/rqyc4mpfUt/KE9TMW8/l0bfeZoulalyz65YIquX3Jo+T32OAc0P0/xm8nil5qjR2xf79EAd06cfytQm6nhEK86uqWMVbfebCI+lSYePH9AnM9LrrD5r9NH56RKVK/KzD2i/perb9m6+fv2C9h/8ii75xGqehufFMT/YpxeNPKzSWyDO/XdLnscjZxToYkl8fvdpvIfW3KEb1u8O0Nw2VmwyixgbVsZsYTow8wnd++0q3fgv79n/XtjtqncLpMDd7BSfb9TFSRclWhLHlblzw6qBLz8XNUmVOLGicrwoFE7R2NKeNf7xz1/QOtA28mqVLshjMUZopcElsLyb0rY+3aXKz+1JuNOMwhQtCXu++7Sxh1WucD3dXaO5s57jIj98TYwHYix40XoPbaYF6iuh+n3VHMTMKinVrXlLSBiFedIeb6pbNF8Uxk8MavPHYZCSxlwJzbHPdDuzN0OzW3y8TtZxn6UGM8R4hGDbLlkVSeQ1sTr2/edCVoVjBdO7HdmgkeUnke9tN248ldWEQdN2e3phEWfn7tI37Vt7D8CW4qyW5vlTy3QJ40pdL0GrPO2gxZj0aFHdI8uTpeKHnWel4X0z6WDlA2sCmR/7DPe465jCPtmTYGPmjp439GCZhtT91pcFJu3cUHawgQfUzlUq33eWFrZ50v+vaMlydIjW1FjSCo7ozoz93Ot5nRWqUIB1DqKlWpkWAl5+tvFGtubIrkCtbtLV4HJf4tQMXh6z4E68ONyHU7S4WVavcLRxyT2f8HxuYXgxOFbr6cHaMyqpZ71WWpGC6thSrGkuJTpB/+pz3Yl9DYg9FvQfi3POdUa6M3ibGWTT778OdpyWfvoZF8cz0QpvO2g9PIRjfJ3eBEpNNvSgOql+ZGvxkiRIgXs/E/Q35kHVFqiul1aIsuWDmGckGH/q59XqBfvZyRWpYSrVNuN5dDU9zxJ27WTT1wQOKnvCueW2Z8HJqEB1ZlSGGBy9C5lYJPEboTso+4TZcaj2wILJRavL5xbDs9tTVnWO/PA8bfZwYFeqTsypPaGyWk5M4wk9ErNNZ1koZ1yijU7HSvABWbQwoxvE8f4ahStdy7nnxIPabYjEmJIAux+niyVVybTltdL16ICOwePphqyHoko7t2Qc+BBNlBpPHL3lW9ESOz1Aq3EFX/8N0p4PshjRq5s6H2Je2kYbi5i9DB0v2QSp25uleNx+48IDDls0q87Palc3E52DPZ4VhTZq/5lnUqCaB8uWsByY+4yWuOcn4WyXGzLtWQJ78I/H7JpvPEnuhep92LJOGi+wEKfLbPkw1ZKGG9doN31D0iJ2FzyBLFqjSYqdSkWc6+QqaVbvawvc8y+b/lKeCuloIpWYK467vhkC+DmijUvOM2GQxlyrDh7uchxWyHobbzOnITq4vuTxHEl8b0p15xZNyPC8fJGm1z0vaZJqU94E5hyFr37rhwq0H+aA0g454CvLoiUZF02hJwY0VilaRAYF6itaHxcXXHma/Mt8SeLQuCHT9xz6BsXjMLt+tEinnfPR9iIfJzyBnniTnZv2xP58+sT+nkeuG/fhYHnI++1IoyuxS/cNyFhltSmgqwRipbSTW1tLeYZ4f+LpiIfbbwwhjDthioEebPd2qgk3H5xRD73rxFVrakBVjNWWfVA5U2VIz9DIsj2pNv+dVsfHrRWz6t4ijchnZmCS1jUMuBviF+OgytJmKU+zxNl2TiDkS7vsqor9HhDv75AwypxAtR86L1bPv7kjiUFK5zk8brPrVF7k4wQT6HpLQQ4mHZTttCf29TtHy00E3PgnWmLy1bGZj6Y47nK8aSiBWCm9CUaVNq+KPtxsfBRLR3Mi+01WYZtjUk30jt0KWW/jiaukITwSZwOnXNnapPsfnfbZ+D+tjNC5SSdMrUTbOjVJeeaguKVv8/f0N++p9xU/or0urjTxPqGrWdKMR/bKdoqY/ibIlkBV7mM+uPjj0HRnCAJuyLRd2OLhHErxW5nFFIO1cz4n0xPkCfRk99MJM7E/23yskd8gdPDZMrdo1vU4hS+jZSHeNJxArJTGGr+dN7kV8VEsFr2luV5BM/hWuBLGzkm88pVJl5RBO/AcQmmzxFRpr2yLUPk9A5NLVrq/tVvTdF5WbRp4n0p3eaYVk969q1eTX950NsCGtPw8/Zt6n+Tf5p39CIFmXKEvYtIztw/PTursL5Ak11X2ynan80NnSKA6qUP8VST8CWajYo5YTIhGy8/bjxt30zdsgYe0HvHgf7NrdYxRnrRdJo++tkoPw2Zv5iFtl0bplJW2KE+nRufp7nPWeaxE1CWaGPK+L39KbgS4S/xtLu7uY502Rp8Fa6zJ47k1ofJ7GtR3ZprKe8kex9q3+1QpTdBQQaa1Ur9l9NGZiRJVHod75mpPVmn6jP1+o+8MTZcfEr9ctef3qXxt1C0TJ7+vMHqNVh829vSlM4CsxrPVUm6uYnRNoDaIP3XiTXM/+O/0h256AUJJGCulct22Kj7KvWfaS2DHhRo9v1+ma6ODyjbJJuzT0ERgsI8njS0I8ub2ZLRwCLa6GLxkxSrGAgaxulemaRnPKP6mZZcsG15vl8zDx/Z1cAoKWLZVXMvK18kG+7rxwD9m1N4+pf39bxvcH5MOH67S9YkzKk+zOhZ2X2vP79L8qPoN637d0vM+Joat7qTZH8CpvaWnuzI3c4UqVo7mXfpfvxyqD9M7ukNzpePmN08+mU4a32+tbHehPHh2BOqrdRoXHaZfzIp9nXbLzrcVfyHthOJu4vF7/0SXf+B85jR9+KnzumwP6LHqbNJwOInMZfunyz9wf+f0h5+yz9yjBzEG1Tx8SOUpNQPLF2niupe0vVK+ZufNzE/Sbd/NPaLtuQErLkYmyf3VJSWkVOytFG1TBenVukjXyxX7OCp/Z4sJ8T6jUKqvVVx7Trvqd2X7rRC/zvnkLt50X7fabmCgUfGWTtJeL5mvppiq7lF5uqiMWoEusmuwVrqoZrgGnV3Y8d/fZys0Ysi0TWvi/H7uei2t6hiWgB8W35mn4elbtKa+7xM33VOeJv0XNQCLQ06yHPjVklVGzr12TcciB3N6dk6gRs+UnXhT52/dT5lST5L0WCYdLItz1ajhrYsXu5skb2yPI+zA+qS9bGon4HZsxhqVLsp+pxHbm9YWhGC++zPtP3CO4VP6kMWPBu16fdEIIbQt0aLab0s0an1Wtot00/2sbLv+Sb/PLv3CjmEUn7MmPw3t0oAYp+SZmfRy44o4XyECz3vXssIKSOhuupRiedJKV2dQ4WJJ/aa4J++Le2WM0PLqDfWdBk19/r36VJAq7SycFccojvuac08+oStinHGO5fCgbJ13Ycr2RN5bm7VtYQv7lQebgLZhv4dl+4SoWv13Z7x/SEtjhWOYOo6tlOpOpgPx/bHxv1bKz+6kSMyIQFUeqzCFHvAAaW2U4Gl1tL0f6XaHVncW6KxjvGYqoZ7Nozsz1sPgS4hriSDmLWZCvDhzRRgJuVHFP2OXeDnYGseb8Hyu8dfNEctshyM7nkaJfM2DdWU8hXA+uxA6265uXlX3kQ9wdqJhY3yd7NvOZoLGj+jKzIC17FwJXlS+Kz42jox9X4IZuj/uOXnwfj18Y4dsVylROGxq/BsF3Wvly+nqte6nTKnH73mO8YJbgqK11Z88cZ8mPs6PrMBiVXJpS3vbwGumC4/pCwonMaH5zU9ssRK3eSS1LdCAl6lM04f4htFYT5NKgO7ajBR2qbhIGzKGPTSmm/fLRpNVKXJnXPFZl+IusJFT5hIND5lWNl6K2WBqDrYhUKZ1dO99dYvmlHhNMibqw0J4wj1PTeH2X7ni5qxqXlhVY83xwrOTmv0iEN8fPcbbz40h+kuCntoyMiFQnRrpoRdJ+0J6pMpz54vV0wsadlNXiBYbm6FEtnfsKiSBiSa/y10YonJEImEmHOPjTZhRbbRb1RLL/WLW7500F8J2rsFwTGvGrX4nNoUH27Tm5LuzQhJ4bGxgSTfy+/i5xXm30tRrDhxDK1Jz8YFRto7FNPqFsYy5qznVrfJjtPT7NX/N+gymVNLLQGDHR9WtvjQJj1dsavz8j3t0mV/nNjTtDAcx2PG78vtCnnnuKIiY9DdlC3Tg/WhomZLOGfhqQuyGO2WXZtzOkMYuiRYmBhV84hX3bPExJur59oeqhY9d9r11PLsB+BjLbIB/ot6GjAd/EpNK9f2JM6xo4DiG3HNIWFGul/DspObqnG+yJ1rEQ2g/N81tEG6G7gtUp0a6mHGG7mvguy5F0wkC1vccMrRn1woVkmC9Py42w8mjKTqH6yxQM20utrkxiBO7XMjGdmptL7ISy774LVbOLW7p90gIIOUtCcYO18ONtz3Lt0SwIYy98zHfvY7b6MIHjLjJRIoZOjOaVksxEAbxL7N3MA9qQBgPXZ2zQkQ8z1Z97HbX60sH8Megh3uHLI9cOwogsMlgUwJVesH+aC/vtqc9oK9bcO6e3QyJuf6ypISSQYVSSIxvk7ZAB277dDeDeOivkNlLw2yylsouxXuHtQSq7hjDJw+hY5eKxY3wHvKJGJ/IuyV/RQsvCfuKbk8P0uCgaFZ8rf69tGDCWMfxlBjTKfEtjr+YfD9FL+GNMbrhYzzLkWiyIpv6i4vKaGCF26mXOk3XBeqzFZnKJ25pLulOXh63pj/rkykpnN9oPJvz16n3lkZr9NZacntB+w8qVL6uNhwZBZrbZMs8bz6ny4MT5JXF54Yt/gHjQjZ26ZnHmMR6D9/Q55cH6f1/ZKKJC5vIpXGvModsjXf3+b0LMjzhy4+HaGhh2z023wAk7nNkp+ADRmxcYgqBykRJos9FwsW+bM1vuNKFP9N2E+Liygb5Nup/FYi37Xp96QCB+1GXKswSRm2Kj2qZQO0NuGgyzl6m8u/26cVbxwNo0rvvhG377l1Iv2zeFujAbV9yjzFfTYhfIZN2afBnXzRnl2I9w9zeR60A+ceYuN9t7Bn+kj4eGqSffRF+0vy6+u+FiuHd/Ybehf54lb6W8cGffqjGC72VR5d2C9QTRHKBGvD2hzhiLG3WlthjfborUFVt3HiD5l+mbBhL6PMcMu9cLP7ZdcN0TAGvbngzqK8wStO3Ku6mrEi0BZe+kOVe5GSd3+9Vi/So+TIG8OWwKPz3MWyA0RXf2gNGCwRqs4bTv/wmJjPiOJLY8PQE4k/FJHByNaxEa3Cnc8aSl8eG+NjCqG3xUSdMoAY9/U4z+grRmUgkbbAF9fB8vgk9dRKtSXc423NejGdL7BJ/pqPsvW/iGDcmNXldfEJFV9wEcDy4YV64OCBQW0ZygeqfkNbF91ve+9bG9KehiwLVP0PUbo2Mi7bnkKM/u5b4lkRyF+iTr/mGhSgvQzTahk3byKbzIluwOsNxMYn+wUxj5szz0gqDW7/Epiu+k0wmui1QA+mqOpqmwy8C4p6rYKxWpjZL8QmnaHxpV1aOKfLQmVZzwgSq3BQz6y7Th7SIGL7W24IwktnoIMlWyDi6domVnBQtTsjy+P6oIhB8eT3W0cL3Tmg7ZBg+r2/chtNoHGdI3F6FUJoQqNbxHvOWhDQClTux/J58e9waEB0zYTdrOV0TqNbgImZ8Vzde+MVdSKv8tXfTGuWzTOU5TDi79hnkJOmLQtE3bNrnlsqLbOMznpFCJVCdSGPm7I8lDBlgdLwKkkTnxgY13cmKb/BsTqB6m05kS7hjuVn4My1a7DIq330sW6Y2S/mFtnsfVXzUOTEoJh2TdWnZJqleorpHq9ec3MwhrS4EpA22IAweG57Y5iZcIePo2iVfTF/cxk2d+NvANY2zXTz+NKkHU6C/GhWFcz4pvLdt3iR1kki8SUrgDwHzHFlWTH//VepgwahIuiRQ7YfaSy8Uj98VHZdGId1yBzeYOmUNfQJV20sbhaZh84mIBnGMqY0WX+7tj8kX549faWxc/AbXmLlTd834PYjbAKEnoB3Yceou6wUqL6Uuc+ls/lPfo5vvsFX4jU/jNEk+j41o2dks5X/WnPtoxUdFbaxsEWm8ElG0N83UdxExgs0hj/np7hrND/PKOcFr0XpbEIZv1SpxBSluY5Nl5dC1S76JbZyQ/Yot3Ue+z7+BJc4zmT6US6LvHInEcRik8d6mWeECoXgaKd6B5yOwWmjdAhXTf6nlO07T0RWB+kp0eiNBOUL/ElLMYOFbDgwRsip9yBVfPTJ/rF59vXZbtBlXviDnU77jabZjaRo2k8cy8t2Y5i7dHBqiv/3f/6Fe8ButeuOmYkyH/oH+r3rFhRtP7imxfmOQpv7ZUc/+QalhjXtfjFrY/eMlWeMMZbSAfnV7mgZ//D/phfq3DRsMtb0uKgeiOpZ6YVuj53fn7TJ68u/5Ik3XxXZ6+SRlM0bKzdWFT0wg/lRn6c53j0TLzGYp/7NhGWAVHxW/U7x5PK9EMlFTR6bTTFVpx0o6L74nP8Y2bnKqVPmx81vBa9FqWxAOTzeW+Fz5akLIZhDbtg7RP9QZRF275BeycZNaPhH0ZfP48mMaGrxMn1vX1r9qED3EcLHPQ7me0WcT3F4Lq/V818748MeX4qwcdJwj9k79v7oZfk5uSkfuCKk9p7vz561KVUbfBxHPlIT9ftOOnpMMe06ThGnUrRYe2DH9mo7DTtB5gWpVJcglKkfoF6gxMZWxnkO107Rud2X87NpepvWLIV+eVU2BWt2ap+mV+uVIPcPGRZN/E4IdP8gNfQMvskpdUu8hi94cZRtwnm7KL4DiLwHf4RuV31XTwxEloMX/yZ3yYUtU3sYr/ZmlHX7iHA8/b5MOVPLtuco+vXj9mp7el1VmeA7ZKu0tyswU9ufzYyua4lR897qqKZ0fptJOMzPYiGXxWALCPNaDHkcrz8OGb56TomZkxGhZOdM4XK+EdrGPKNqdZipQBSkBPlsm2uTt8CpE7qS3buLSalsQhn+JXi9m1SPexto5dMNTMGnapcDxRYcQ8O/jq2DK9rqTaC76Y0R8tUI/tt4jGvdgWnbSOw5fflouRLlwj5jA27YweuOb0zdd7211hxYuTlH5D3+mbzZL9P5AnGeXjVW6K1wgBPa8JMmxHdjs3T8yQsWO7pNoTIcFqlPN4lKinIX+TUkxRpC5rINLTaaYLZwTHa3edc2WGYKdVMW51WUZ4MvtDTuWVwmkPuhY17BxwcFjtuwH0z/j4cYtGN9VFTMtYVBCl0b5ZgBuPO2A6eCsim+siVsO5ommI5e5uaGMuZ5RGx2OxG/0R+Re9AYnfW+NvGePFj1Ph+sBtQx//e9YEyg5Iao9p4pboUmWctyuqwQWyZvbNMlFZTNxoPx6iqabxicoVnSXX3208jwUdemyBoRgbPI7G8P6Ud1k9/jgm/xHDU5uuEp4Oq+W2oJQdIViOPwcg15Qu6pVxGqepl2Kts8B+PdxQayy2XAh503KIhwywQpS7Bm1vLRMsPIsBNwO8pW20Ems8xuR5y7GxyH5eeUIkZWnzs/ZRQyY+InzeKdxIIAgnoZJFpIWcGSI/t3RfRIadFCgspJtf303JN1NDEx4yhY54LId/Lyzmy83aEbM5MKNIrtJvCPKcpAzQkxHVA2xwxTk5yKqcwjMd9/Q3TlZ+ziq7jQ3vHGbBcKO0fHmBXfW8h38vNMrz15kNQ0mUN1lMJMO78ok6GLWHXxuuYEMvUbifm/OqTKwBhXmNiPFGvdwxMWwcaHiTlLUzmMd8dtw+dFHlbbmvHKgA5OrtP0/5HGGGFL53PWfpWFVFtAoTFH5YbC8YQN49gnVkh2vh/aKQ5DgZqk0OVtbeB4uvv4f3d9aCqu00jiusndxxOV7Fz6i3/sS5Do49dvZRC1IC21BKE1tkIqwG4Lq3iLJuvNRnlxdu6QtZNkKn/d9KhwomG+Sbc6qS5Ree0Krk+Iz+bwdmiGbE5er+jD/jBefmKfhkj0OOV5VQ5x/6HGbh7QpjytyvBA4IlSI4bvfVOjK1CK5ufDFM/Ev1yZo4vq/xK4geZu0mi8nfGJhS/XJ4oi5Myumf3eRtgpU8/AxPZBLUJUyXb/Ian8bBZpaqtC93eeRQtWNmbm3RqX3RUdxPita//giVdTy1oPHTAhwQ1mcpTXx98qSXG4MSVDuooSe9d1Fml2Tx7tEU0JsyHrLG+EfEniG2z0fdUz31m7RhxNFy3jEihUeAxLrpWFLY/2X6FfiN9bmZdyYGKx5AQCF56nop/FFeVxqo4MsbxlZTYN5DY0f0S/5b0QJAlar2ShcpJK8dur8p9XGCqPvPJXqalFzeJxXg41trLLKuZ+L83Lu08gyRVQUFHjiPrnQsONNh307mp1rKs+1QuXStBuPKs/12urDZIOvQ9DzKJrupge3n8kmrolTC91uQ/Q3v1Z/E+2PYc9z7Tntir9VliZdD5fTjLNzVj+K/GyQJs4jEtZPWl3ONBJXdKTYndxLuDYzT8WJ61SueM9KpXydJop2P5YTtOg+JmiJLYiATVBS7TRn6bOcscO2bXkaW9qLeJ707RIXwLFV4tjGSeNHvxTXp0JLU2JcFHZ5pU4ZyFAZpz8O0KQaXyrla5Y9ssemQ2t1y/ptISR/URHfJ4VrYJLglBJ/74c37L68Zts0S5AcOtfGoLOXy/a4ulaii/Jexo4XTFwaQigP/oRWv/xz8s16bPKRapNWFghOyuMmKW3AE/lJVxf4M969cqZxtFWg+pcWQlpktY2/0GdjIe8PaXXLkGJ2+Rs3TYpBfWcmqHQ3Wgjb1OjJb67RqFWuTXxn3xmaKN3ViOsy6fBxhUoTQywti0zQP0QTH96iyv638b/76jZNSXGTH6abuw06p/mSNuf5ecWVbhPHtX2LJs7YZd5y+VPxibYdxKx5uxT4jUaeQPGZh6tiIBs65c7mZWLvITnY3Y+qQMIR4vumFPNiEjF1u2HHru6VaZqf1/xmxMTDge1UTWs4at/SfkUMtKODVHA2R6nfHxwcpWkxGZH/5t4ZHzK37Fij2CC5wvBTu/JYvs/aYKAX3/w93Z5Ux6PRwlYf6pbQQ5tOAnZJ2vOIwcnNG1kDvfW4XuhUu5N7DNGHH1dKog8X7Pul7nn+1CCNTgs7xp0AcTRtC8LhG6R0w1WCmIfbdGvijDq/PJ0avUarsbZN3y4dbc9bMdf54nzD59M+Dtt5YU0Kpsuxdrn6dYXmR737Isem6TKbBPvGBXEMw/O0WWcQpQd73h3f5MbOiZJnN83Dh77UYvlTYvzSGP/c+NOfr1H5+sWUceeeFy9dmqvssHPjPes8Umd+SUVz45u9aS9JPHhn6fwmKQA6jBdb2aYyo8rDE5UOpipmuHLJTR/baPf+0nKvnoe3eSNTRQtOJDxOv039F6TACQnzlubtfR7itYSTOncyGFseNus4oXVxe0nagRcmmJ3UgK0DAhUcf1hsZVs6sbMEGTKDNQ83aXaAZwLQwQ5LSOstyg49eh5uKqSk9w00T43eytyubjU+FqcfutMedAUn/tSX1sjZrOMtNUsva1RmCBe3v6XNHJIB3BSXyTfxNYOdYUf8bqaKq7QOCFRwInAT/Lcjv6cbI9dPl36tljLNd/TN/b+jMblslnRgteIfk2QdyCg9eh5Orsos5QM8EZgHtDKmlqFzebryhRhx2Wah4+gh6lWcuEf/srwSqI5olY6BAR3h5KU4TJU5JAs4cagdjT/1UgN2Iu1eN4BABScDc5cWrM0AbZils00c9S1pQvkj8XXCWPe8t6hHz8P1tre/EADwE0xzJjfXuRtAenr59/jhxJ/6V0e+pJK0sVamBXvzcUFXOLkbYHszjMNJ2dXR+FPH85yx3KWtBAIVnBjsnIeiQ7d6lsvTzARa0hKndmJsnvi/N+nV83Di4epzFoN249usZ6W2s3Mwy7i+rJReBJI39PlUnoyCynnKsDaxWpkf5Aaw9QRpi4SgXbb7Xr+wmdntezV6fr9M10bVRkBZSXB9h1atmPVOxp8qB4Dc4JSx3KWtBAIVnCBUzkHRqcMSjqfHrmTlDq6qJc4rp9Lh1BWG6DV69TxUwvROZgsADKsQhuw7Z+inq7+lyi/s9H9JJ3mgR3FTnmV09ULmRpeFWMTkaVFlgLD3GDg2Py6XeWtxqh1mMXdpK4FABScLxwiGFR9oAvNgXXkOhNEIpoLRZP/jIuVDvBK9Rm+exzNaUc9FZGJy0GZUejy3H52n+YYpAsGxwslZ25FqcUnwnBtBb767v6GuzOgRffGzQRosyLSICQqmNOJom+asa3T8J9IQqODkoZKKZ2/2WaPasRiNe+08avRkWXrrOlSlCgAQiXmwYm0uzZLn3C6nLURhyCZbJ/40LJ1e7e1r+uMvZR7fq9RsQT0LnQpfxwgIVHAyqe7R4ohB+el/pQZJUMAx5/vPp+xlu5iqOQCAzmGXJzeo+PG+eqWbeCFc9ZXCnJzJUdXGVB7fOu9qOvZvFig3MBNT4fJ4AYEKAAAAABCGW441ZJnezX8aEX9qbtGscRyKrnQHCFQAAAAAgDDcNIIhy/RO/tPxdQrNz29leOl0danjAwQqAAAAAEAYjkANSU/oxJ86Za5lkQ+eG9ZOneZUl6rSXvky/ee/KlDhg886mNC/d4FABQAAAAAIwynrGhCoXoopJ/5UxqryQgMq/nRomQ5kFoCFy7Ty5JC25wtk5GZpS70LRAOBCgAAAAAQyhFtz8kUU+do2do5b9K7/7NKk4WzNHxW5m21Y1NlIZgBX6nWXVroz1H/f/s1Vebn1cYm8V0LozTx97vsfSAKCFQAAAAAgCjMl7Q5P0qn8tJjalDf+XnalIKzukOl8zLPaY7ywyXa4YlA3AqD79EPf1qm3z22k/sDfSBQAQAAAABayJv1cSFO5e7+Gn37h4/onBC2M3fgN00CBCoAAAAAQMswafMqj1vdoRvv5ehcWf7rGZVn6hP+g3ogUAEAAAAAWoYdf+rlP92mOSNHVzdNq47+f61L+A/CgEAFAAAAAGgVf/ln+iBfoNKuE3Vq0sHKB3TqVIEGJ1YyVmI7u0CgAgAAAACATAGBCgAAAAAAMgUEKgAAAAAAyBQQqAAAAAAAIFNAoAIAAAAAgEwBgQoAAAAAADIFBCoAAAAAAMgUEKgAAAAAACBTQKACAAAAAIBMAYEKAAAAAAAyBQQqAAAAAADIFBCoAAAAAAAgQxD9f8ngMReDmpgiAAAAAElFTkSuQmCC)\r\n",
        "\r\n",
        "As the softmax normalization is done on the key, its values decide the amount of importance given to the query.\r\n",
        "\r\n",
        "The output represents the multiplication of the attention weights and the value vector. This ensures that the words we want to focus on are kept as is and the irrelevant words are flushed out.\r\n",
        "\r\n",
        "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax. \r\n",
        "\r\n",
        "For example, consider that query and key have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of dk. Hence, square root of dk is used for scaling (and not any other number) because the matmul of query and key should have a mean of 0 and variance of 1, so that we get a gentler softmax.\r\n",
        "\r\n",
        "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of query and key and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpN-sXJIcKeK"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\r\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\r\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\r\n",
        "\r\n",
        "  # scale matmul_qk\r\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\r\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\r\n",
        "\r\n",
        "  # add the mask to zero out padding tokens\r\n",
        "  if mask is not None:\r\n",
        "    logits += (mask * -1e9)\r\n",
        "\r\n",
        "  # softmax is normalized on the last axis (seq_len_k)\r\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\r\n",
        "\r\n",
        "  output = tf.matmul(attention_weights, value)\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxQN5S4tdO-d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0nT6FrOc0Nu"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\r\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\r\n",
        "    self.num_heads = num_heads\r\n",
        "    self.d_model = d_model\r\n",
        "\r\n",
        "    assert d_model % self.num_heads == 0\r\n",
        "\r\n",
        "    self.depth = d_model // self.num_heads\r\n",
        "\r\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "\r\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "\r\n",
        "  def split_heads(self, inputs, batch_size):\r\n",
        "    inputs = tf.reshape(\r\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\r\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\r\n",
        "        'value'], inputs['mask']\r\n",
        "    batch_size = tf.shape(query)[0]\r\n",
        "\r\n",
        "    # linear layers\r\n",
        "    query = self.query_dense(query)\r\n",
        "    key = self.key_dense(key)\r\n",
        "    value = self.value_dense(value)\r\n",
        "\r\n",
        "    # split heads\r\n",
        "    query = self.split_heads(query, batch_size)\r\n",
        "    key = self.split_heads(key, batch_size)\r\n",
        "    value = self.split_heads(value, batch_size)\r\n",
        "\r\n",
        "    # scaled dot-product attention\r\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\r\n",
        "\r\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\r\n",
        "\r\n",
        "    # concatenation of heads\r\n",
        "    concat_attention = tf.reshape(scaled_attention,\r\n",
        "                                  (batch_size, -1, self.d_model))\r\n",
        "\r\n",
        "    # final linear layer\r\n",
        "    outputs = self.dense(concat_attention)\r\n",
        "\r\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2-W3-ZCdR_A"
      },
      "source": [
        "def create_padding_mask(x):\r\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\r\n",
        "  # (batch_size, 1, 1, sequence length)\r\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INf48QadUD4"
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iFyB8yWdVi6"
      },
      "source": [
        "def create_look_ahead_mask(x):\r\n",
        "  seq_len = tf.shape(x)[1]\r\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\r\n",
        "  padding_mask = create_padding_mask(x)\r\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQNz3WXLdXHe"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoBfPZ_ldZTB"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "  def __init__(self, position, d_model):\r\n",
        "    super(PositionalEncoding, self).__init__()\r\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\r\n",
        "\r\n",
        "  def get_angles(self, position, i, d_model):\r\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\r\n",
        "    return position * angles\r\n",
        "\r\n",
        "  def positional_encoding(self, position, d_model):\r\n",
        "    angle_rads = self.get_angles(\r\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\r\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\r\n",
        "        d_model=d_model)\r\n",
        "    # apply sin to even index in the array\r\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\r\n",
        "    # apply cos to odd index in the array\r\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\r\n",
        "\r\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\r\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\r\n",
        "    return tf.cast(pos_encoding, tf.float32)\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weNS4A2pdavl"
      },
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\r\n",
        "\r\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\r\n",
        "plt.xlabel('Depth')\r\n",
        "plt.xlim((0, 512))\r\n",
        "plt.ylabel('Position')\r\n",
        "plt.colorbar()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XFCbcZtdcLT"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n",
        "\r\n",
        "  attention = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention\")({\r\n",
        "          'query': inputs,\r\n",
        "          'key': inputs,\r\n",
        "          'value': inputs,\r\n",
        "          'mask': padding_mask\r\n",
        "      })\r\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\r\n",
        "  attention = tf.keras.layers.LayerNormalization(\r\n",
        "      epsilon=1e-6)(inputs + attention)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\r\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n",
        "  outputs = tf.keras.layers.LayerNormalization(\r\n",
        "      epsilon=1e-6)(attention + outputs)\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjemSA2xdd0L"
      },
      "source": [
        "def encoder(vocab_size,\r\n",
        "            num_layers,\r\n",
        "            units,\r\n",
        "            d_model,\r\n",
        "            num_heads,\r\n",
        "            dropout,\r\n",
        "            name=\"encoder\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n",
        "\r\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\r\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n",
        "  for i in range(int(num_layers)):\r\n",
        "    outputs = encoder_layer(\r\n",
        "        units=units,\r\n",
        "        d_model=d_model,\r\n",
        "        num_heads=num_heads,\r\n",
        "        dropout=dropout,\r\n",
        "        name=\"encoder_layer_{}\".format(i),\r\n",
        "    )([outputs, padding_mask])\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS6J-b4Vdfeh"
      },
      "source": [
        "sample_encoder = encoder(\r\n",
        "    vocab_size=8192,\r\n",
        "    num_layers=2,\r\n",
        "    units=512,\r\n",
        "    d_model=128,\r\n",
        "    num_heads=4,\r\n",
        "    dropout=0.3,\r\n",
        "    name=\"sample_encoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opqgTKh7dg7z"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\r\n",
        "  look_ahead_mask = tf.keras.Input(\r\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n",
        "\r\n",
        "  attention1 = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\r\n",
        "          'query': inputs,\r\n",
        "          'key': inputs,\r\n",
        "          'value': inputs,\r\n",
        "          'mask': look_ahead_mask\r\n",
        "      })\r\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\r\n",
        "      epsilon=1e-6)(attention1 + inputs)\r\n",
        "\r\n",
        "  attention2 = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\r\n",
        "          'query': attention1,\r\n",
        "          'key': enc_outputs,\r\n",
        "          'value': enc_outputs,\r\n",
        "          'mask': padding_mask\r\n",
        "      })\r\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\r\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\r\n",
        "      epsilon=1e-6)(attention2 + attention1)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\r\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n",
        "  outputs = tf.keras.layers.LayerNormalization(\r\n",
        "      epsilon=1e-6)(outputs + attention2)\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n",
        "      outputs=outputs,\r\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Mlvu2ddisD"
      },
      "source": [
        "sample_decoder_layer = decoder_layer(\r\n",
        "    units=512,\r\n",
        "    d_model=128,\r\n",
        "    num_heads=4,\r\n",
        "    dropout=0.3,\r\n",
        "    name=\"sample_decoder_layer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEWwX-izdkOO"
      },
      "source": [
        "def decoder(vocab_size,\r\n",
        "            num_layers,\r\n",
        "            units,\r\n",
        "            d_model,\r\n",
        "            num_heads,\r\n",
        "            dropout,\r\n",
        "            name='decoder'):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\r\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\r\n",
        "  look_ahead_mask = tf.keras.Input(\r\n",
        "      shape=(1, None, None), name='look_ahead_mask')\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n",
        "  \r\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\r\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n",
        "\r\n",
        "  for i in range(int(num_layers)):\r\n",
        "    outputs = decoder_layer(\r\n",
        "        units=units,\r\n",
        "        d_model=d_model,\r\n",
        "        num_heads=num_heads,\r\n",
        "        dropout=dropout,\r\n",
        "        name='decoder_layer_{}'.format(i),\r\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n",
        "      outputs=outputs,\r\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHHHVPkjdl1J"
      },
      "source": [
        "def transformer(vocab_size,\r\n",
        "                num_layers,\r\n",
        "                units,\r\n",
        "                d_model,\r\n",
        "                num_heads,\r\n",
        "                dropout,\r\n",
        "                name=\"transformer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\r\n",
        "\r\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\r\n",
        "      create_padding_mask, output_shape=(1, 1, None),\r\n",
        "      name='enc_padding_mask')(inputs)\r\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\r\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\r\n",
        "      create_look_ahead_mask,\r\n",
        "      output_shape=(1, None, None),\r\n",
        "      name='look_ahead_mask')(dec_inputs)\r\n",
        "  # mask the encoder outputs for the 2nd attention block\r\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\r\n",
        "      create_padding_mask, output_shape=(1, 1, None),\r\n",
        "      name='dec_padding_mask')(inputs)\r\n",
        "\r\n",
        "  enc_outputs = encoder(\r\n",
        "      vocab_size=vocab_size,\r\n",
        "      num_layers=num_layers,\r\n",
        "      units=units,\r\n",
        "      d_model=d_model,\r\n",
        "      num_heads=num_heads,\r\n",
        "      dropout=dropout,\r\n",
        "  )(inputs=[inputs, enc_padding_mask])\r\n",
        "\r\n",
        "  dec_outputs = decoder(\r\n",
        "      vocab_size=vocab_size,\r\n",
        "      num_layers=num_layers,\r\n",
        "      units=units,\r\n",
        "      d_model=d_model,\r\n",
        "      num_heads=num_heads,\r\n",
        "      dropout=dropout,\r\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\r\n",
        "\r\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nrRicIGdnnZ"
      },
      "source": [
        "def loss_function(y_true, y_pred):\r\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n",
        "  \r\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\r\n",
        "\r\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\r\n",
        "  loss = tf.multiply(loss, mask)\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzJcYN55dpDF"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "\r\n",
        "  def __init__(self, d_model, warmup_steps=4000):\r\n",
        "    super(CustomSchedule, self).__init__()\r\n",
        "\r\n",
        "    self.d_model = d_model\r\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\r\n",
        "\r\n",
        "    self.warmup_steps = warmup_steps\r\n",
        "\r\n",
        "  def __call__(self, step):\r\n",
        "    arg1 = tf.math.rsqrt(step)\r\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\r\n",
        "\r\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXXT4Dwudr4j"
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\r\n",
        "\r\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\r\n",
        "plt.ylabel(\"Learning Rate\")\r\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWwoLFJndtrH"
      },
      "source": [
        " # clear backend\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "learning_rate = CustomSchedule(D_MODEL)\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(\r\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n",
        "\r\n",
        "def accuracy(y_true, y_pred):\r\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\r\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buuwFs0Kdu3F"
      },
      "source": [
        "# initialize and compile model within strategy scope\r\n",
        "with strategy.scope():\r\n",
        "  model = transformer(\r\n",
        "      vocab_size=VOCAB_SIZE,\r\n",
        "      num_layers=NUM_LAYERS,\r\n",
        "      units=UNITS,\r\n",
        "      d_model=D_MODEL,\r\n",
        "      num_heads=NUM_HEADS,\r\n",
        "      dropout=DROPOUT)\r\n",
        "\r\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqBvY-fcd03N"
      },
      "source": [
        "import datetime\r\n",
        "\r\n",
        "#32% - 80 epok, po 30 epokach - 29\r\n",
        "\r\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "\r\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WnSjyh-d3IC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}