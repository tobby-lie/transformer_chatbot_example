{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_chatbot_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1T39h16jbjhgnGqPjgiQCVi31nbmG9aq3",
      "authorship_tag": "ABX9TyOhRfz/hv5RjIMmpSRJmqdv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobby-lie/transformer_chatbot_example/blob/main/Transformer_chatbot_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUvE71z2Upns",
        "outputId": "66b3b0bf-0a93-4910-928b-609ee5d3543f"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "if 'google.colab' in sys.modules:\r\n",
        "  %tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf.random.set_seed(1234)\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "#!pip install tensorflow-datasets==1.2.0\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "import os\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBsrrhM3UsXH",
        "outputId": "cd6c769b-e852-4100-c7c2-7a0a32cf53c7"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4hiqNjgUwLa",
        "outputId": "ce2e3b1a-ae15-4426-c7fd-6c949146d451"
      },
      "source": [
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPLICAS: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM8AK6HPU34t"
      },
      "source": [
        "# Maximum sentence length\r\n",
        "MAX_LENGTH = 30\r\n",
        "\r\n",
        "# For tf.data.Dataset\r\n",
        "BATCH_SIZE = int(64 * strategy.num_replicas_in_sync)\r\n",
        "BUFFER_SIZE = 20000\r\n",
        "\r\n",
        "# For Transformer\r\n",
        "NUM_LAYERS = 2 #6\r\n",
        "D_MODEL = 256 #512\r\n",
        "NUM_HEADS = 8\r\n",
        "UNITS = 512 #2048\r\n",
        "DROPOUT = 0.1\r\n",
        "\r\n",
        "EPOCHS = 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZAWviXeU5ao"
      },
      "source": [
        "# Need to add data.txt from final output data everytime this notebook is run"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFe9f6cmU9qH"
      },
      "source": [
        "def textPreprocess(input_text):\r\n",
        "\r\n",
        "  def removeAccents(input_text):\r\n",
        "      strange='ąćęłńóśżź'\r\n",
        "      ascii_replacements='acelnoszz'\r\n",
        "      translator=str.maketrans(strange,ascii_replacements)\r\n",
        "      return input_text.translate(translator)\r\n",
        "\r\n",
        "  def removeSpecial(input_text):\r\n",
        "      special='[^A-Za-z0-9 ]+'\r\n",
        "      return re.sub(special, '', input_text)\r\n",
        "\r\n",
        "  def removeTriplicated(input_text):\r\n",
        "      return re.compile(r'(.)\\1{2,}', re.IGNORECASE).sub(r'\\1', input_text)\r\n",
        "\r\n",
        "  return removeTriplicated(removeSpecial(removeAccents(input_text.lower())))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSpJ0XVcVZc_"
      },
      "source": [
        "initiates = []\r\n",
        "responses = []\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/OSN_Project/data.txt', 'r', encoding=\"utf-8\") as file:\r\n",
        "    lines = file.readlines()\r\n",
        "    for line in lines:\r\n",
        "        if '|||' in line:\r\n",
        "            initiates.append(line.split('|||')[0])\r\n",
        "            responses.append(line.split('|||')[1])\r\n",
        "#             print(line.split('|||'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoLH5QxzVajj",
        "outputId": "ea2f1a38-54a3-4590-86e3-18162e912aa0"
      },
      "source": [
        "len(initiates)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaRQA7NlVmYH",
        "outputId": "ae369e14-3627-48ae-8184-80a06d040d49"
      },
      "source": [
        "len(responses)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2620icYWu2O",
        "outputId": "8ab83b58-3cbc-4d53-bbd5-ed1f11474280"
      },
      "source": [
        "print('Sample initiation: {}'.format(initiates[20]))\r\n",
        "print(\"\\n\")\r\n",
        "print('Sample response: {}'.format(responses[20]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample initiation: congrats to you and to all of the virtual conference speakers . hopefully , we will still socialize in the evenings and mornings like irl . just think - - no long lines for the restrooms and elevators . \n",
            "\n",
            "\n",
            "Sample response:  thanks ! yes , i think some online socializing is a great idea - i will miss the dancing , tho !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7A3SLmPXBH-"
      },
      "source": [
        "text_preprocessor = lambda x: textPreprocess(x)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVtr8CAVXDzU"
      },
      "source": [
        "initiates_preprocessed = list(map(text_preprocessor, initiates))\r\n",
        "responses_preprocessed = list(map(text_preprocessor, responses))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "hQha_kcxXErQ",
        "outputId": "790a73e8-4679-46ff-a6a6-57e310bf684f"
      },
      "source": [
        "initiates_preprocessed[20]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'congrats to you and to all of the virtual conference speakers  hopefully  we will still socialize in the evenings and mornings like irl  just think no long lines for the restrooms and elevators  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sCTqT-AeXGHj",
        "outputId": "f93a72ff-2977-4144-b32c-48a5a9dacee3"
      },
      "source": [
        "responses_preprocessed[20]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' thanks  yes  i think some online socializing is a great idea  i will miss the dancing  tho '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wyrhHrNXHMK"
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\r\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\r\n",
        "    initiates_preprocessed + responses_preprocessed, target_vocab_size=2**13)\r\n",
        "\r\n",
        "# Define start and end token to indicate the start and end of a sentence\r\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\r\n",
        "\r\n",
        "# Vocabulary size plus start and end token\r\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R7pSdSWXNq4",
        "outputId": "3446c365-b20a-49b0-c361-1ac98a334a18"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(initiates_preprocessed[20])))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [2009, 4, 8, 7, 4, 40, 9, 3, 2138, 3885, 4265, 8062, 1, 6496, 175, 1, 29, 37, 98, 4662, 1804, 12, 3, 4212, 1188, 7, 968, 13, 34, 2992, 8055, 1, 30, 70, 64, 224, 1786, 15, 3, 7772, 6312, 13, 7, 7656, 3987, 8062, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0J41WN-YjE3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}